{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "1. Projects -- Proposals due 4/12 !\n",
    "2. SVM\n",
    "3. Boosting\n",
    "4. Ensembles; SuperLearners\n",
    "5. Review: Bagging vs Boosting vs Ensembles\n",
    "6. Into to GRIDSEARCH\n",
    "7. Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "SVM:\n",
    "* Supervised learning\n",
    "* Used for Regression or Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/svm_example.jpg\" alt=\"drawing\" style=\"width: 1200px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"Kernel: A kernel is a similarity function for pattern analysis. It must be one of rbf/linear/poly/sigmoid/precomputed; default = “rbf” (radial basis function). Choosing the appropriate kernel will result in a better model fit\"\n",
    "\n",
    "\"Mastering Machine Learning with Python in Six Steps...\" - Manohar Swamynathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Description of fnlwgt (final weight)\n",
    "|\n",
    "| The weights on the CPS files are controlled to independent estimates of the\n",
    "| civilian noninstitutional population of the US.  These are prepared monthly\n",
    "| for us by Population Division here at the Census Bureau.  We use 3 sets of\n",
    "| controls.\n",
    "|  These are:\n",
    "|          1.  A single cell estimate of the population 16+ for each state.\n",
    "|          2.  Controls for Hispanic Origin by age and sex.\n",
    "|          3.  Controls by Race, age and sex.\n",
    "|\n",
    "| We use all three sets of controls in our weighting program and \"rake\" through\n",
    "| them 6 times so that by the end we come back to all the controls we used.\n",
    "|\n",
    "| The term estimate refers to population totals derived from CPS by creating\n",
    "| \"weighted tallies\" of any specified socio-economic characteristics of the\n",
    "| population.\n",
    "|\n",
    "| People with similar demographic characteristics should have\n",
    "| similar weights.  There is one important caveat to remember\n",
    "| about this statement.  That is that since the CPS sample is\n",
    "| actually a collection of 51 state samples, each with its own\n",
    "| probability of selection, the statement only applies within\n",
    "| state.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNum</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>287927</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  WorkClass  fnlwgt  Education  EducationNum  MaritalStatus  \\\n",
       "32555   27          4  257302          7            12              2   \n",
       "32556   40          4  154374         11             9              2   \n",
       "32557   58          4  151910         11             9              6   \n",
       "32558   22          4  201490         11             9              4   \n",
       "32559   52          5  287927         11             9              2   \n",
       "\n",
       "       Occupation  Relationship  Race  Gender  CapitalGain  CapitalLoss  \\\n",
       "32555          13             5     4       0            0            0   \n",
       "32556           7             0     4       1            0            0   \n",
       "32557           1             4     4       0            0            0   \n",
       "32558           1             3     4       1            0            0   \n",
       "32559           4             5     4       0        15024            0   \n",
       "\n",
       "       HoursPerWeek  NativeCountry  Income  \n",
       "32555            38             39       0  \n",
       "32556            40             39       1  \n",
       "32557            40             39       0  \n",
       "32558            20             39       0  \n",
       "32559            40             39       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "col_names = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "df = pandas.read_csv('adult.data')\n",
    "df.columns=col_names\n",
    "df['Income'] = df['Income'].apply(lambda x: 0 if x == ' <=50K' else 1)\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == type(object):\n",
    "        le = sklearn.preprocessing.LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='Income')\n",
    "y = df['Income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=555, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.792 (+/- 0.001)\n",
      "Test Accuracy: 0.794 \n",
      "Wall time: 16min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# SVM TAKES A LONG TIME !!\n",
    "\n",
    "# Run in another notebook.\n",
    "\n",
    "SVM = SVC(random_state=0, probability=True)\n",
    "\n",
    "# Remember what is happening in cross validation ????\n",
    "scores = sklearn.model_selection.cross_val_score(SVM, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std()))\n",
    "SVM.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(SVM.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Boosting\n",
    "\n",
    "\"The core concept of boosting is that rather than an independent individual hypothesis, combining hypotheses in a sequential order increases the accuracy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/boosting_ada.jpg\" alt=\"drawing\" style=\"width: 900px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/boosting_w_weights.jpg\" alt=\"drawing\" style=\"width: 900px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common types of Boosting you will see:\n",
    "1. AdaBoost  \n",
    "2. Gradient Boost\n",
    "3. XGBoost (Extreme Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Bagging and Boosting\n",
    "* Sequential ensemble of models:  Boosting\n",
    "\n",
    "* Parallel ensemble of models:  Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.864 (+/- 0.003) [GBC]\n",
      "Test Accuracy: 0.865 \n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier(n_estimators = 100)\n",
    "scores = sklearn.model_selection.cross_val_score(GBC, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), 'GBC'))\n",
    "GBC.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(GBC.predict(X_test), y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86466011, 0.86261261, 0.86527437, 0.86036036, 0.86793612])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Hey that's pretty good!\n",
    "\n",
    "#### Let's compare to other estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.864 (+/- 0.002) [ADBC]\n",
      "Test Accuracy: 0.864 \n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# We can specify a base model with AdaBoost.  Defaults to DecisionTreeClassifier\n",
    "\n",
    "ADBC = AdaBoostClassifier(n_estimators = 100)\n",
    "scores = sklearn.model_selection.cross_val_score(ADBC, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), 'ADBC'))\n",
    "ADBC.fit(X_train, y_train)\n",
    "print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(ADBC.predict(X_test), y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CV Accuracy: 0.814 (+/- 0.006) [DT]\n",
      "Train CV Accuracy: 0.772 (+/- 0.002) [KNN]\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# What if we apply boosting to a KNN model instead of the DT ?\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_ab = AdaBoostClassifier(n_estimators = 100, base_estimator=dt)\n",
    "# knn_ab = AdaBoostClassifier(n_estimators = 100, base_estimator=knn)\n",
    "scores = sklearn.model_selection.cross_val_score(dt_ab, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), 'DT'))\n",
    "# knn.fit(X_train, y_train)\n",
    "scores_knn = sklearn.model_selection.cross_val_score(knn, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "# print(\"Test Accuracy: %0.3f \" % (sklearn.metrics.accuracy_score(knn.predict(X_test), y_test)))\n",
    "print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores_knn.mean(), scores_knn.std(), 'KNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "Train CV Accuracy: 0.795 (+/- 0.008) [Logistic Regression]\n",
      "Test Accuracy: 0.8034 \n",
      "Train CV Accuracy: 0.856 (+/- 0.004) [Random Forest]\n",
      "Test Accuracy: 0.8575 \n",
      "Train CV Accuracy: 0.772 (+/- 0.002) [KNeighbors]\n",
      "Test Accuracy: 0.7792 \n",
      "Train CV Accuracy: 0.809 (+/- 0.004) [Decision Tree]\n",
      "Test Accuracy: 0.8152 \n",
      "Train CV Accuracy: 0.864 (+/- 0.002) [Ada Boost]\n",
      "Test Accuracy: 0.8636 \n",
      "Train CV Accuracy: 0.849 (+/- 0.003) [Bagging]\n",
      "Test Accuracy: 0.8585 \n",
      "Train CV Accuracy: 0.864 (+/- 0.002) [Gradient Boosting]\n",
      "Test Accuracy: 0.8650 \n",
      "Train CV Accuracy: 0.866 (+/- 0.002) [XGBoost]\n",
      "Test Accuracy: 0.8709 \n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR = LogisticRegression(solver='lbfgs', max_iter=10000, random_state=555)\n",
    "RF = RandomForestClassifier(n_estimators = 100, random_state=555)\n",
    "SVM = SVC(random_state=0, probability=True)\n",
    "KNC = KNeighborsClassifier()\n",
    "DTC = DecisionTreeClassifier()\n",
    "ABC = AdaBoostClassifier(n_estimators = 100)\n",
    "BC = BaggingClassifier(n_estimators = 100)\n",
    "GBC = GradientBoostingClassifier(n_estimators = 100)\n",
    "# clf_XGB = XGBClassifier(n_estimators = 100, objective= 'binary:logistic', seed=555, use_label_encoder=False)\n",
    "clf_XGB = XGBClassifier(n_estimators = 100, seed=555, use_label_encoder=False, eval_metric='logloss')\n",
    "clfs = []\n",
    "print('5-fold cross validation:\\n')\n",
    "for clf, label in zip([LR, RF, KNC, DTC, ABC, BC, GBC, clf_XGB],\n",
    "                      ['Logistic Regression',\n",
    "                       'Random Forest',\n",
    "                       #'Support Vector Machine',\n",
    "                       'KNeighbors',\n",
    "                       'Decision Tree',\n",
    "                       'Ada Boost',\n",
    "                       'Bagging',\n",
    "                       'Gradient Boosting',\n",
    "                       'XGBoost']):\n",
    "    scores = sklearn.model_selection.cross_val_score(clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    print(\"Train CV Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    md = clf.fit(X_train, y_train)\n",
    "    clfs.append(md)\n",
    "    print(\"Test Accuracy: %0.4f \" % (sklearn.metrics.accuracy_score(clf.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9090     1\n",
       "16487    0\n",
       "20301    0\n",
       "22508    0\n",
       "1260     1\n",
       "        ..\n",
       "21348    0\n",
       "10582    1\n",
       "22634    0\n",
       "23939    0\n",
       "28337    0\n",
       "Name: Income, Length: 8140, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if we want to create our own custom ensemble ??\n",
    "\n",
    "### This is python.  There is a library for that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion: Super Learners.\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/ensemble.jpg\" alt=\"drawing\" style=\"width: 900px;\"/>\n",
    "</center>\n",
    "\n",
    "#### Also known as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import make_scorer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#We'll use threading.  Discuss: threads vs processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# --- Build ---\n",
    "# Passing a scoring function will create cv scores during fitting\n",
    "# the scorer should be a simple function accepting to vectors and returning a scalar\n",
    "ensemble = SuperLearner(scorer=accuracy_score, random_state=555, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...0AF4160>)],\n",
       "   n_jobs=-1, name='group-0', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x00000210D0AF4160>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the first layer\n",
    "ensemble.add([KNC, LR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...0AF4160>)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x00000210D0AF4160>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach the final meta estimator\n",
    "# ensemble.add_meta(LogisticRegression())\n",
    "ensemble.add_meta(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:04\n",
      "Processing layer-2             done | 00:00:01\n",
      "Fit complete                        | 00:00:06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4782, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...0AF4160>)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=555, sample_size=20,\n",
       "       scorer=<function accuracy_score at 0x00000210D0AF4160>,\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit ensemble\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:02\n",
      "Accuracy - Train :  0.7996723996723997\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:01\n",
      "Accuracy - Test :  0.8034398034398035\n"
     ]
    }
   ],
   "source": [
    "#pred_vals = ensemble.predict(X_test)\n",
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(ensemble.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(ensemble.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit data:\n",
      "                                 score-m  score-s  ft-m  ft-s  pt-m  pt-s\n",
      "layer-1  kneighborsclassifier       0.77     0.00  0.52  0.05  4.30  0.05\n",
      "layer-1  logisticregression         0.80     0.00  2.88  0.29  0.01  0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit data:\\n%r\" % ensemble.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try some GridSearch\n",
    "\n",
    "xg_params = {\n",
    "    'eta': [0.01, 0.025, 0.05, 0.075, 0.25, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 6, 7, 9],\n",
    "    'tree_method': ['auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "seed = 555\n",
    "#kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='logloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, mono...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     seed=555, subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'eta': [0.01, 0.025, 0.05, 0.075, 0.25, 0.3, 0.5],\n",
       "                         'max_depth': [3, 5, 6, 7, 9],\n",
       "                         'tree_method': ['auto']},\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf_XGB = XGBClassifier(n_estimators = 100, objective= 'binary:logistic', seed=555)\n",
    "clf_XGB = XGBClassifier(n_estimators = 100, seed=555, use_label_encoder=False, eval_metric='logloss')\n",
    "grid2 = GridSearchCV(clf_XGB, xg_params, scoring=\"roc_auc\", cv=5, verbose=10, n_jobs=-1)\n",
    "grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'eta': 0.25, 'max_depth': 3, 'tree_method': 'auto'}\n",
      "Accuracy - Train CV:  0.8699017199017198\n",
      "Accuracy - Train :  0.8770270270270271\n",
      "Accuracy - Test :  0.8716216216216216\n"
     ]
    }
   ],
   "source": [
    "print ('Best Parameters: ', grid2.best_params_)\n",
    "results = sklearn.model_selection.cross_val_score(grid2.best_estimator_, X_train,y_train, cv=5)\n",
    "print (\"Accuracy - Train CV: \", results.mean())\n",
    "print (\"Accuracy - Train : \", sklearn.metrics.accuracy_score(grid2.best_estimator_.predict(X_train), y_train))\n",
    "print (\"Accuracy - Test : \", sklearn.metrics.accuracy_score(grid2.best_estimator_.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
